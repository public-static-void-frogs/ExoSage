{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:42:07.223202Z",
     "iopub.status.busy": "2025-10-04T23:42:07.222950Z",
     "iopub.status.idle": "2025-10-04T23:42:07.498107Z",
     "shell.execute_reply": "2025-10-04T23:42:07.497341Z",
     "shell.execute_reply.started": "2025-10-04T23:42:07.223184Z"
    },
    "trusted": true
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:42:08.173641Z",
     "iopub.status.busy": "2025-10-04T23:42:08.172959Z",
     "iopub.status.idle": "2025-10-04T23:42:14.505017Z",
     "shell.execute_reply": "2025-10-04T23:42:14.504292Z",
     "shell.execute_reply.started": "2025-10-04T23:42:08.173615Z"
    },
    "trusted": true
   },
   "source": [
    "!pip install fastparquet"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:42:14.507309Z",
     "iopub.status.busy": "2025-10-04T23:42:14.506727Z",
     "iopub.status.idle": "2025-10-04T23:42:14.510825Z",
     "shell.execute_reply": "2025-10-04T23:42:14.510264Z",
     "shell.execute_reply.started": "2025-10-04T23:42:14.507286Z"
    },
    "trusted": true
   },
   "source": [
    "NANS_IN_THE_MIDDLE_THRESHOLD = 15000 "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:42:14.512155Z",
     "iopub.status.busy": "2025-10-04T23:42:14.511645Z",
     "iopub.status.idle": "2025-10-04T23:42:14.527484Z",
     "shell.execute_reply": "2025-10-04T23:42:14.527017Z",
     "shell.execute_reply.started": "2025-10-04T23:42:14.512138Z"
    },
    "trusted": true
   },
   "source": [
    "def sort_num(el):\n",
    "    num = re.search(r\"version_02_(\\w+)_(.+)\\..+\", el)\n",
    "    part = num.group(2)\n",
    "    if part == 'final':\n",
    "        return float('inf')\n",
    "    else:\n",
    "        return int(part)\n",
    "FOLDERS = ['/kaggle/input/nasa-cooked/init_df/', '/kaggle/input/nasa-cooked/init_df_not_in_koi/']\n",
    "START_INDEX = 0\n",
    "END_INDEX = -1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:42:14.528931Z",
     "iopub.status.busy": "2025-10-04T23:42:14.528742Z",
     "iopub.status.idle": "2025-10-04T23:42:14.562963Z",
     "shell.execute_reply": "2025-10-04T23:42:14.562332Z",
     "shell.execute_reply.started": "2025-10-04T23:42:14.528915Z"
    },
    "trusted": true
   },
   "source": [
    "parquets = []\n",
    "csvs = []\n",
    "for f in FOLDERS:\n",
    "    l = os.listdir(f)\n",
    "    print(l)\n",
    "    parquets.append([el for el in l if el.endswith('.parquet')])\n",
    "    csvs.append([el for el in l if el.endswith('.csv')])\n",
    "    \n",
    "    parquets[-1].sort(key=sort_num)\n",
    "    csvs[-1].sort(key=sort_num)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:42:14.917212Z",
     "iopub.status.busy": "2025-10-04T23:42:14.916724Z",
     "iopub.status.idle": "2025-10-04T23:43:12.830259Z",
     "shell.execute_reply": "2025-10-04T23:43:12.829401Z",
     "shell.execute_reply.started": "2025-10-04T23:42:14.917177Z"
    },
    "trusted": true
   },
   "source": [
    "dfs_to_concat = []\n",
    "for f, csv_list, parquet_list in zip(FOLDERS, csvs, parquets):\n",
    "    print(f'using folder {f}')\n",
    "    for pair in zip(csv_list[START_INDEX:END_INDEX], parquet_list[START_INDEX:END_INDEX]):\n",
    "        print(f'concating pair {pair}')\n",
    "        df_values_loaded = pd.read_parquet(f + pair[1], engine=\"fastparquet\")\n",
    "        df_values_loaded.columns = df_values_loaded.columns.astype(int)\n",
    "        df_ids_loaded = pd.read_csv(f + pair[0])\n",
    "        print(f'{df_values_loaded.shape=}, {df_ids_loaded.shape=}')\n",
    "        if df_values_loaded.shape[0] > df_values_loaded.shape[1]: \n",
    "            print('concating with transpose')\n",
    "            df_part = pd.concat([df_ids_loaded, df_values_loaded.T.reset_index(drop=True)], axis=1)\n",
    "        else: \n",
    "            print('concating without transpose')\n",
    "            df_part = pd.concat([df_ids_loaded, df_values_loaded], axis=1)\n",
    "        print(f'{df_part.shape=}')\n",
    "        df_part.set_index(['KEPID', 'PLANET_NUM'], inplace=True)\n",
    "        dfs_to_concat.append(df_part)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:12.831928Z",
     "iopub.status.busy": "2025-10-04T23:43:12.831630Z",
     "iopub.status.idle": "2025-10-04T23:43:12.835639Z",
     "shell.execute_reply": "2025-10-04T23:43:12.834814Z",
     "shell.execute_reply.started": "2025-10-04T23:43:12.831901Z"
    },
    "trusted": true
   },
   "source": [
    "del parquets, csvs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:12.836772Z",
     "iopub.status.busy": "2025-10-04T23:43:12.836528Z",
     "iopub.status.idle": "2025-10-04T23:43:16.872547Z",
     "shell.execute_reply": "2025-10-04T23:43:16.871795Z",
     "shell.execute_reply.started": "2025-10-04T23:43:12.836750Z"
    },
    "trusted": true
   },
   "source": [
    "full_df = pd.concat(dfs_to_concat, axis=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:16.874184Z",
     "iopub.status.busy": "2025-10-04T23:43:16.873981Z",
     "iopub.status.idle": "2025-10-04T23:43:16.925055Z",
     "shell.execute_reply": "2025-10-04T23:43:16.924331Z",
     "shell.execute_reply.started": "2025-10-04T23:43:16.874168Z"
    },
    "trusted": true
   },
   "source": [
    "del dfs_to_concat"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:16.926241Z",
     "iopub.status.busy": "2025-10-04T23:43:16.925971Z",
     "iopub.status.idle": "2025-10-04T23:43:16.957998Z",
     "shell.execute_reply": "2025-10-04T23:43:16.957236Z",
     "shell.execute_reply.started": "2025-10-04T23:43:16.926219Z"
    },
    "trusted": true
   },
   "source": [
    "full_df['LABEL'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:16.959244Z",
     "iopub.status.busy": "2025-10-04T23:43:16.958912Z",
     "iopub.status.idle": "2025-10-04T23:43:20.438369Z",
     "shell.execute_reply": "2025-10-04T23:43:20.437584Z",
     "shell.execute_reply.started": "2025-10-04T23:43:16.959222Z"
    },
    "trusted": true
   },
   "source": [
    "mask = full_df['LABEL'] == 1\n",
    "subset = full_df[mask]\n",
    "full_df = full_df.drop(subset.index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:20.439610Z",
     "iopub.status.busy": "2025-10-04T23:43:20.439436Z",
     "iopub.status.idle": "2025-10-04T23:43:20.444921Z",
     "shell.execute_reply": "2025-10-04T23:43:20.444294Z",
     "shell.execute_reply.started": "2025-10-04T23:43:20.439596Z"
    },
    "trusted": true
   },
   "source": [
    "del mask, subset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:20.446083Z",
     "iopub.status.busy": "2025-10-04T23:43:20.445789Z",
     "iopub.status.idle": "2025-10-04T23:43:31.928799Z",
     "shell.execute_reply": "2025-10-04T23:43:31.928258Z",
     "shell.execute_reply.started": "2025-10-04T23:43:20.446059Z"
    },
    "trusted": true
   },
   "source": [
    "last_valid_pos = full_df.apply(lambda row: row.last_valid_index(), axis=1).map(\n",
    "    lambda idx: full_df.columns.get_loc(idx) if idx is not None else np.nan\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:31.929847Z",
     "iopub.status.busy": "2025-10-04T23:43:31.929576Z",
     "iopub.status.idle": "2025-10-04T23:43:37.327721Z",
     "shell.execute_reply": "2025-10-04T23:43:37.326975Z",
     "shell.execute_reply.started": "2025-10-04T23:43:31.929809Z"
    },
    "trusted": true
   },
   "source": [
    "nan_count = full_df.isna().sum(axis=1)\n",
    "print(nan_count)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:37.330458Z",
     "iopub.status.busy": "2025-10-04T23:43:37.330229Z",
     "iopub.status.idle": "2025-10-04T23:43:37.337709Z",
     "shell.execute_reply": "2025-10-04T23:43:37.336903Z",
     "shell.execute_reply.started": "2025-10-04T23:43:37.330440Z"
    },
    "trusted": true
   },
   "source": [
    "row_len = full_df.shape[1] \n",
    "diff = row_len - last_valid_pos\n",
    "print(diff)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:37.338646Z",
     "iopub.status.busy": "2025-10-04T23:43:37.338460Z",
     "iopub.status.idle": "2025-10-04T23:43:37.354241Z",
     "shell.execute_reply": "2025-10-04T23:43:37.353503Z",
     "shell.execute_reply.started": "2025-10-04T23:43:37.338631Z"
    },
    "trusted": true
   },
   "source": [
    "del last_valid_pos"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:37.355225Z",
     "iopub.status.busy": "2025-10-04T23:43:37.354980Z",
     "iopub.status.idle": "2025-10-04T23:43:37.369380Z",
     "shell.execute_reply": "2025-10-04T23:43:37.368907Z",
     "shell.execute_reply.started": "2025-10-04T23:43:37.355200Z"
    },
    "trusted": true
   },
   "source": [
    "mask_nans_in_the_middle = (nan_count - diff) > NANS_IN_THE_MIDDLE_THRESHOLD"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:37.370209Z",
     "iopub.status.busy": "2025-10-04T23:43:37.370055Z",
     "iopub.status.idle": "2025-10-04T23:43:37.383995Z",
     "shell.execute_reply": "2025-10-04T23:43:37.383293Z",
     "shell.execute_reply.started": "2025-10-04T23:43:37.370195Z"
    },
    "trusted": true
   },
   "source": [
    "del diff, nan_count"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:37.385141Z",
     "iopub.status.busy": "2025-10-04T23:43:37.384803Z",
     "iopub.status.idle": "2025-10-04T23:43:39.171985Z",
     "shell.execute_reply": "2025-10-04T23:43:39.171049Z",
     "shell.execute_reply.started": "2025-10-04T23:43:37.385119Z"
    },
    "trusted": true
   },
   "source": [
    "df_cleaned = full_df[~mask_nans_in_the_middle]\n",
    "del full_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:39.173088Z",
     "iopub.status.busy": "2025-10-04T23:43:39.172834Z",
     "iopub.status.idle": "2025-10-04T23:43:39.177417Z",
     "shell.execute_reply": "2025-10-04T23:43:39.176715Z",
     "shell.execute_reply.started": "2025-10-04T23:43:39.173073Z"
    },
    "trusted": true
   },
   "source": [
    "del mask_nans_in_the_middle, row_len"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:39.178785Z",
     "iopub.status.busy": "2025-10-04T23:43:39.178254Z",
     "iopub.status.idle": "2025-10-04T23:43:40.869828Z",
     "shell.execute_reply": "2025-10-04T23:43:40.869049Z",
     "shell.execute_reply.started": "2025-10-04T23:43:39.178768Z"
    },
    "trusted": true
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def remove_outliers_torch(\n",
    "    df: pd.DataFrame,\n",
    "    sigma: float = 3.0,\n",
    "    method: str = \"median\",\n",
    "    fill_value=float(\"nan\"),\n",
    "    batch_size: int = 2048,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    if n_gpus == 0:\n",
    "        raise RuntimeError(\"No CUDA device detected\")\n",
    "\n",
    "    device_list = [f\"cuda:{i}\" for i in range(n_gpus)]\n",
    "\n",
    "    data_cpu = torch.tensor(df.to_numpy(dtype=\"float32\"), device=\"cpu\")\n",
    "    n_rows = data_cpu.shape[0]\n",
    "    result_cpu = torch.empty_like(data_cpu)\n",
    "\n",
    "    splits = torch.chunk(data_cpu, n_gpus)\n",
    "    results_cpu = []\n",
    "\n",
    "    for i, chunk in enumerate(splits):\n",
    "        device = device_list[i]\n",
    "        out_gpu = _process_chunk_gpu(chunk, sigma, method, fill_value, batch_size, device)\n",
    "        results_cpu.append(out_gpu.to(\"cpu\"))  \n",
    "\n",
    "    result = torch.cat(results_cpu, dim=0)\n",
    "    return pd.DataFrame(result.numpy(), index=df.index, columns=df.columns)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def _process_chunk_gpu(\n",
    "    data_chunk: torch.Tensor,\n",
    "    sigma: float,\n",
    "    method: str,\n",
    "    fill_value: float,\n",
    "    batch_size: int,\n",
    "    device: str,\n",
    ") -> torch.Tensor:\n",
    "    data_chunk = data_chunk.to(device, non_blocking=True)\n",
    "    n_rows = data_chunk.shape[0]\n",
    "    result = torch.empty_like(data_chunk)\n",
    "\n",
    "    for start in range(0, n_rows, batch_size):\n",
    "        end = min(start + batch_size, n_rows)\n",
    "        batch = data_chunk[start:end]\n",
    "\n",
    "        nan_mask = torch.isnan(batch)\n",
    "\n",
    "        if method == \"median\":\n",
    "            center = torch.nanmedian(batch, dim=1, keepdim=True).values\n",
    "        else:\n",
    "            center = torch.nanmean(batch, dim=1, keepdim=True)\n",
    "\n",
    "        diff = batch - center\n",
    "        diff[nan_mask] = 0\n",
    "        count = (~nan_mask).sum(dim=1, keepdim=True).clamp(min=1)\n",
    "        var = (diff ** 2).sum(dim=1, keepdim=True) / count\n",
    "        std = torch.sqrt(var)\n",
    "\n",
    "        mask = (torch.abs(batch - center) > sigma * std) & ~nan_mask\n",
    "\n",
    "        if torch.isnan(torch.tensor(fill_value)):\n",
    "            batch = torch.where(mask, torch.tensor(float(\"nan\"), device=device), batch)\n",
    "        else:\n",
    "            batch = torch.where(mask, torch.tensor(fill_value, device=device), batch)\n",
    "\n",
    "        result[start:end] = batch\n",
    "\n",
    "    return result\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:40.871014Z",
     "iopub.status.busy": "2025-10-04T23:43:40.870671Z",
     "iopub.status.idle": "2025-10-04T23:43:57.107377Z",
     "shell.execute_reply": "2025-10-04T23:43:57.106597Z",
     "shell.execute_reply.started": "2025-10-04T23:43:40.870995Z"
    },
    "trusted": true
   },
   "source": [
    "df_removed_outliers = remove_outliers_torch(df_cleaned)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:57.108448Z",
     "iopub.status.busy": "2025-10-04T23:43:57.108197Z",
     "iopub.status.idle": "2025-10-04T23:43:57.115519Z",
     "shell.execute_reply": "2025-10-04T23:43:57.114886Z",
     "shell.execute_reply.started": "2025-10-04T23:43:57.108427Z"
    },
    "trusted": true
   },
   "source": [
    "df_removed_outliers[\"LABEL\"] = df_cleaned[\"LABEL\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:57.117654Z",
     "iopub.status.busy": "2025-10-04T23:43:57.117367Z",
     "iopub.status.idle": "2025-10-04T23:43:57.166034Z",
     "shell.execute_reply": "2025-10-04T23:43:57.165282Z",
     "shell.execute_reply.started": "2025-10-04T23:43:57.117629Z"
    },
    "trusted": true
   },
   "source": [
    "df_removed_outliers.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:57.167092Z",
     "iopub.status.busy": "2025-10-04T23:43:57.166815Z",
     "iopub.status.idle": "2025-10-04T23:43:57.182668Z",
     "shell.execute_reply": "2025-10-04T23:43:57.182074Z",
     "shell.execute_reply.started": "2025-10-04T23:43:57.167071Z"
    },
    "trusted": true
   },
   "source": [
    "del df_cleaned"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:57.183728Z",
     "iopub.status.busy": "2025-10-04T23:43:57.183464Z",
     "iopub.status.idle": "2025-10-04T23:43:57.198162Z",
     "shell.execute_reply": "2025-10-04T23:43:57.197483Z",
     "shell.execute_reply.started": "2025-10-04T23:43:57.183713Z"
    },
    "trusted": true
   },
   "source": [
    "import numpy as np\n",
    "n = df_removed_outliers.shape[1] // 2\n",
    "def fill_nan_fourier(row, n_components=n):\n",
    "    x = np.arange(len(row))\n",
    "    y = row.values.copy()\n",
    "    mask = ~np.isnan(y)\n",
    "    x_valid = x[mask]\n",
    "    y_valid = y[mask]\n",
    "    \n",
    "    if len(y_valid) == 0:\n",
    "        return row  \n",
    "    \n",
    "    y_interp = np.interp(x, x_valid, y_valid)\n",
    "    fft_coeffs = np.fft.rfft(y_interp)\n",
    "    if n_components:\n",
    "        fft_coeffs[n_components:] = 0\n",
    "    y_smooth = np.fft.irfft(fft_coeffs, n=len(y_interp))\n",
    "    \n",
    "    y_filled = row.copy()\n",
    "    y_filled = row.astype(np.float32).copy()\n",
    "    y_filled[np.isnan(row)] = y_smooth[np.isnan(row)].astype(np.float32)\n",
    "    return y_filled\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:43:57.199081Z",
     "iopub.status.busy": "2025-10-04T23:43:57.198835Z",
     "iopub.status.idle": "2025-10-04T23:43:57.219612Z",
     "shell.execute_reply": "2025-10-04T23:43:57.218966Z",
     "shell.execute_reply.started": "2025-10-04T23:43:57.199061Z"
    },
    "trusted": true
   },
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:44:00.752813Z",
     "iopub.status.busy": "2025-10-04T23:44:00.752557Z",
     "iopub.status.idle": "2025-10-04T23:46:13.418794Z",
     "shell.execute_reply": "2025-10-04T23:46:13.418218Z",
     "shell.execute_reply.started": "2025-10-04T23:44:00.752794Z"
    },
    "trusted": true
   },
   "source": [
    "df_filled = df_removed_outliers.apply(fill_nan_fourier, axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:46:13.420231Z",
     "iopub.status.busy": "2025-10-04T23:46:13.420021Z",
     "iopub.status.idle": "2025-10-04T23:46:13.426030Z",
     "shell.execute_reply": "2025-10-04T23:46:13.425307Z",
     "shell.execute_reply.started": "2025-10-04T23:46:13.420205Z"
    },
    "trusted": true
   },
   "source": [
    "df_filled[\"LABEL\"] = df_removed_outliers[\"LABEL\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:46:13.427039Z",
     "iopub.status.busy": "2025-10-04T23:46:13.426798Z",
     "iopub.status.idle": "2025-10-04T23:46:13.458326Z",
     "shell.execute_reply": "2025-10-04T23:46:13.457726Z",
     "shell.execute_reply.started": "2025-10-04T23:46:13.427018Z"
    },
    "trusted": true
   },
   "source": [
    "df_filled.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:46:13.460184Z",
     "iopub.status.busy": "2025-10-04T23:46:13.460001Z",
     "iopub.status.idle": "2025-10-04T23:46:13.463632Z",
     "shell.execute_reply": "2025-10-04T23:46:13.462923Z",
     "shell.execute_reply.started": "2025-10-04T23:46:13.460169Z"
    },
    "trusted": true
   },
   "source": [
    "del df_removed_outliers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:46:13.464422Z",
     "iopub.status.busy": "2025-10-04T23:46:13.464257Z",
     "iopub.status.idle": "2025-10-04T23:46:13.481896Z",
     "shell.execute_reply": "2025-10-04T23:46:13.481334Z",
     "shell.execute_reply.started": "2025-10-04T23:46:13.464408Z"
    },
    "trusted": true
   },
   "source": [
    "df_filled.loc[df_filled['LABEL'] == 3, 'LABEL'] = 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:46:13.482722Z",
     "iopub.status.busy": "2025-10-04T23:46:13.482552Z",
     "iopub.status.idle": "2025-10-04T23:46:13.512195Z",
     "shell.execute_reply": "2025-10-04T23:46:13.511616Z",
     "shell.execute_reply.started": "2025-10-04T23:46:13.482708Z"
    },
    "trusted": true
   },
   "source": [
    "df_filled.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:46:13.512960Z",
     "iopub.status.busy": "2025-10-04T23:46:13.512772Z",
     "iopub.status.idle": "2025-10-04T23:46:13.518808Z",
     "shell.execute_reply": "2025-10-04T23:46:13.518040Z",
     "shell.execute_reply.started": "2025-10-04T23:46:13.512946Z"
    },
    "trusted": true
   },
   "source": [
    "df_filled[\"LABEL\"].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:46:13.519968Z",
     "iopub.status.busy": "2025-10-04T23:46:13.519690Z",
     "iopub.status.idle": "2025-10-04T23:46:22.765406Z",
     "shell.execute_reply": "2025-10-04T23:46:22.764833Z",
     "shell.execute_reply.started": "2025-10-04T23:46:13.519946Z"
    },
    "trusted": true
   },
   "source": [
    "df_filled.isna().sum(axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:46:22.766311Z",
     "iopub.status.busy": "2025-10-04T23:46:22.766104Z",
     "iopub.status.idle": "2025-10-04T23:46:22.770221Z",
     "shell.execute_reply": "2025-10-04T23:46:22.769599Z",
     "shell.execute_reply.started": "2025-10-04T23:46:22.766296Z"
    },
    "trusted": true
   },
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:46:22.772528Z",
     "iopub.status.busy": "2025-10-04T23:46:22.772251Z",
     "iopub.status.idle": "2025-10-04T23:46:22.793988Z",
     "shell.execute_reply": "2025-10-04T23:46:22.793461Z",
     "shell.execute_reply.started": "2025-10-04T23:46:22.772513Z"
    },
    "trusted": true
   },
   "source": [
    "\n",
    "def nan_to_zero_and_mask(X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    mask = (~np.isnan(X)).astype(np.float32)\n",
    "    X_filled = np.nan_to_num(X, nan=0.0).astype(np.float32)\n",
    "    return X_filled, mask\n",
    "\n",
    "def robust_scale_rows(X: np.ndarray, mask: np.ndarray, eps=1e-6) -> np.ndarray:\n",
    "    Xn = np.empty_like(X, dtype=np.float32)\n",
    "    for i in range(X.shape[0]):\n",
    "        v = mask[i] > 0\n",
    "        if v.sum() == 0:\n",
    "            Xn[i] = X[i]\n",
    "            continue\n",
    "        med = np.median(X[i, v])\n",
    "        mad = np.median(np.abs(X[i, v] - med)) + eps\n",
    "        Xn[i] = (X[i] - med) / mad\n",
    "    return Xn\n",
    "\n",
    "def uniform_downsample(x: np.ndarray, factor: int) -> np.ndarray:\n",
    "    T = x.shape[-1]\n",
    "    newT = T // factor\n",
    "    return x[..., :newT*factor].reshape(*x.shape[:-1], newT, factor).mean(axis=-1)\n",
    "\n",
    "def extract_local_window(x: np.ndarray, mask: np.ndarray, win_len: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    flux, m = x[0], mask[0]\n",
    "    T = flux.shape[-1]\n",
    "    if win_len >= T:\n",
    "        return x[..., :win_len], mask[..., :win_len]\n",
    "    step = max(1, win_len // 4)\n",
    "    best_s, best_i = -1, 0\n",
    "    for i in range(0, T - win_len + 1, step):\n",
    "        seg = flux[i:i+win_len]\n",
    "        mv = m[i:i+win_len] > 0\n",
    "        if mv.sum() < max(8, win_len//16):  \n",
    "            continue\n",
    "        s = np.var(seg[mv])\n",
    "        if s > best_s:\n",
    "            best_s, best_i = s, i\n",
    "    i = best_i\n",
    "    return x[..., i:i+win_len], mask[..., i:i+win_len]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:59:56.636119Z",
     "iopub.status.busy": "2025-10-04T23:59:56.635687Z",
     "iopub.status.idle": "2025-10-04T23:59:56.643351Z",
     "shell.execute_reply": "2025-10-04T23:59:56.642576Z",
     "shell.execute_reply.started": "2025-10-04T23:59:56.636093Z"
    },
    "trusted": true
   },
   "source": [
    "class BinaryFocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25):\n",
    "        super().__init__(); self.gamma=gamma; self.alpha=alpha; self.reduction=\"mean\"\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        p = torch.sigmoid(logits).clamp(1e-6, 1-1e-6)\n",
    "        ce = nn.functional.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n",
    "        pt = p*targets + (1-p)*(1-targets)\n",
    "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "        loss = alpha_t * (1 - pt).pow(self.gamma) * ce\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        return loss"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:49:07.665568Z",
     "iopub.status.busy": "2025-10-04T23:49:07.664895Z",
     "iopub.status.idle": "2025-10-04T23:49:07.672548Z",
     "shell.execute_reply": "2025-10-04T23:49:07.671829Z",
     "shell.execute_reply.started": "2025-10-04T23:49:07.665547Z"
    },
    "trusted": true
   },
   "source": [
    "class DualViewDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df_X: pd.DataFrame,\n",
    "        y: np.ndarray,\n",
    "        downsample_factor: int = 4,   \n",
    "        local_len: int = 1024\n",
    "    ):\n",
    "        X = df_X.to_numpy(dtype=np.float32, na_value=np.nan)\n",
    "        X, mask = nan_to_zero_and_mask(X)\n",
    "        X = robust_scale_rows(X, mask)  \n",
    "        self.labels = y.astype(np.float32)\n",
    "        self.global_views: List[np.ndarray] = []\n",
    "        self.local_views:  List[np.ndarray] = []\n",
    "        for i in range(X.shape[0]):\n",
    "            flux = X[i][None, :]          \n",
    "            msk  = mask[i][None, :]      \n",
    "            g = np.concatenate([flux, msk], axis=0)  \n",
    "            g_ds = uniform_downsample(g, factor=downsample_factor) \n",
    "            l_win, l_m = extract_local_window(g, np.concatenate([msk, msk], axis=0), local_len)\n",
    "            self.global_views.append(g_ds.astype(np.float32))\n",
    "            self.local_views.append(l_win.astype(np.float32))\n",
    "\n",
    "    def __len__(self): return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        gv = torch.from_numpy(self.global_views[i])  \n",
    "        lv = torch.from_numpy(self.local_views[i])   \n",
    "        y  = torch.tensor(self.labels[i])\n",
    "        return gv, lv, y"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:49:09.727658Z",
     "iopub.status.busy": "2025-10-04T23:49:09.727394Z",
     "iopub.status.idle": "2025-10-04T23:49:09.732097Z",
     "shell.execute_reply": "2025-10-04T23:49:09.731452Z",
     "shell.execute_reply.started": "2025-10-04T23:49:09.727639Z"
    },
    "trusted": true
   },
   "source": [
    "\n",
    "class MaskedGAP(nn.Module):\n",
    "    def forward(self, feats: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
    "        masked = feats * mask\n",
    "        denom = mask.sum(dim=-1).clamp_min(1.0)  \n",
    "        return masked.sum(dim=-1) / denom       "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:49:10.136038Z",
     "iopub.status.busy": "2025-10-04T23:49:10.135330Z",
     "iopub.status.idle": "2025-10-04T23:49:10.142201Z",
     "shell.execute_reply": "2025-10-04T23:49:10.141502Z",
     "shell.execute_reply.started": "2025-10-04T23:49:10.136012Z"
    },
    "trusted": true
   },
   "source": [
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, ch, ks=9, dil=1, p=0.2):\n",
    "        super().__init__()\n",
    "        pad = (ks-1)//2 * dil\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size=ks, dilation=dil, padding=pad),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p),\n",
    "            nn.Conv1d(ch, ch, kernel_size=ks, dilation=dil, padding=pad),\n",
    "            nn.BatchNorm1d(ch),\n",
    "        )\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.net(x) + x)\n",
    "\n",
    "\n",
    "class SE1D(nn.Module):\n",
    "    def __init__(self, ch, r=8):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(ch, ch//r), nn.ReLU(), nn.Linear(ch//r, ch), nn.Sigmoid())\n",
    "    def forward(self, x):         \n",
    "        w = x.mean(dim=-1)           \n",
    "        s = self.fc(w).unsqueeze(-1) \n",
    "        return x * s\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T16:18:03.553595Z",
     "iopub.status.busy": "2025-10-04T16:18:03.553313Z",
     "iopub.status.idle": "2025-10-04T16:18:03.559694Z",
     "shell.execute_reply": "2025-10-04T16:18:03.558913Z",
     "shell.execute_reply.started": "2025-10-04T16:18:03.553575Z"
    },
    "trusted": true
   },
   "source": [
    "class GlobalTCN(nn.Module):\n",
    "    def __init__(self, in_ch=2, width=128, ks=9, dilations=(1,2,4,8,16,32), p=0.2):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, width, kernel_size=5, padding=2, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.blocks = nn.Sequential(*[TCNBlock(width, ks=ks, dil=d, p=p) for d in dilations])\n",
    "        self.gap = MaskedGAP()\n",
    "\n",
    "    def forward(self, x):\n",
    "        flux, mask = x[:, :1, :], x[:, 1:2, :]\n",
    "        h = torch.cat([flux, mask], dim=1)\n",
    "        h = self.stem(h)\n",
    "        h = self.blocks(h)\n",
    "        pooled = self.gap(h, mask)  \n",
    "        return pooled"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:49:13.239500Z",
     "iopub.status.busy": "2025-10-04T23:49:13.239235Z",
     "iopub.status.idle": "2025-10-04T23:49:13.245655Z",
     "shell.execute_reply": "2025-10-04T23:49:13.244966Z",
     "shell.execute_reply.started": "2025-10-04T23:49:13.239479Z"
    },
    "trusted": true
   },
   "source": [
    "class GlobalTCN(nn.Module):\n",
    "    def __init__(self, in_ch=2, width=128, ks=9, dilations=(1,2,4,8,16,32), p=0.2):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, width, kernel_size=5, padding=2, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.blocks = nn.Sequential(*[TCNBlock(width, ks=ks, dil=d, p=p) for d in dilations])\n",
    "        self.se = SE1D(width)\n",
    "        self.gap = MaskedGAP()\n",
    "\n",
    "    def forward(self, x):\n",
    "        flux, mask = x[:, :1, :], x[:, 1:2, :]\n",
    "        h = torch.cat([flux, mask], dim=1)\n",
    "        h = self.stem(h)\n",
    "        h = self.blocks(h)\n",
    "        h = self.se(h)\n",
    "        pooled = self.gap(h, mask)  \n",
    "        return pooled"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:49:14.984585Z",
     "iopub.status.busy": "2025-10-04T23:49:14.983982Z",
     "iopub.status.idle": "2025-10-04T23:49:14.992040Z",
     "shell.execute_reply": "2025-10-04T23:49:14.991184Z",
     "shell.execute_reply.started": "2025-10-04T23:49:14.984561Z"
    },
    "trusted": true
   },
   "source": [
    "class InceptionModule1D(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, ks_list=(3,5,9,15), bottleneck=32):\n",
    "        super().__init__()\n",
    "        self.reduce = nn.Conv1d(in_ch, bottleneck, kernel_size=1)\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Conv1d(bottleneck, out_ch//len(ks_list), kernel_size=ks, padding=ks//2)\n",
    "            for ks in ks_list\n",
    "        ])\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.reduce(x)\n",
    "        outs = [b(x) for b in self.branches]\n",
    "        y = torch.cat(outs, dim=1)\n",
    "        return self.act(self.bn(y))\n",
    "\n",
    "class LocalInception(nn.Module):\n",
    "    def __init__(self, in_ch=2, width=128):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(nn.Conv1d(in_ch, 64, kernel_size=5, padding=2), nn.ReLU())\n",
    "        self.inc1 = InceptionModule1D(64, width)\n",
    "        self.inc2 = InceptionModule1D(width, width)\n",
    "        self.gap  = MaskedGAP()\n",
    "\n",
    "    def forward(self, x):\n",
    "        flux, mask = x[:, :1, :], x[:, 1:2, :]\n",
    "        h = torch.cat([flux, mask], dim=1)\n",
    "        h = self.stem(h)\n",
    "        h = self.inc1(h)\n",
    "        h = self.inc2(h)\n",
    "        pooled = self.gap(h, mask)\n",
    "        return pooled"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T00:00:07.452763Z",
     "iopub.status.busy": "2025-10-05T00:00:07.452240Z",
     "iopub.status.idle": "2025-10-05T00:00:07.460851Z",
     "shell.execute_reply": "2025-10-05T00:00:07.460280Z",
     "shell.execute_reply.started": "2025-10-05T00:00:07.452740Z"
    },
    "trusted": true
   },
   "source": [
    "class DualViewNet(nn.Module):\n",
    "    def __init__(self, gv_width=128, lv_width=128, use_meta=False, meta_dim=0):\n",
    "        super().__init__()\n",
    "        self.global_branch = GlobalTCN(in_ch=2, width=gv_width)\n",
    "        self.local_branch  = LocalInception(in_ch=2, width=lv_width)\n",
    "        in_dim = gv_width + lv_width\n",
    "        if use_meta and meta_dim > 0:\n",
    "            self.meta = nn.Sequential(\n",
    "                nn.Linear(meta_dim, 64), nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(0.2)\n",
    "            )\n",
    "            in_dim += 64\n",
    "        else:\n",
    "            self.meta = None\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(in_dim),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_dim, 128), nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, gv, lv, meta: Optional[torch.Tensor]=None):\n",
    "        g = self.global_branch(gv)  \n",
    "        l = self.local_branch(lv)   \n",
    "        feats = torch.cat([g, l], dim=1)\n",
    "        if self.meta is not None and meta is not None:\n",
    "            feats = torch.cat([feats, self.meta(meta)], dim=1)\n",
    "        logit = self.head(feats).squeeze(1)\n",
    "        return logit"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T00:00:10.414480Z",
     "iopub.status.busy": "2025-10-05T00:00:10.414186Z",
     "iopub.status.idle": "2025-10-05T00:00:10.420932Z",
     "shell.execute_reply": "2025-10-05T00:00:10.420180Z",
     "shell.execute_reply.started": "2025-10-05T00:00:10.414447Z"
    },
    "trusted": true
   },
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, List\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, roc_auc_score,\n",
    "    precision_score, recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "import wandb\n",
    "from typing import Literal"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T00:19:20.819805Z",
     "iopub.status.busy": "2025-10-05T00:19:20.819269Z",
     "iopub.status.idle": "2025-10-05T00:19:20.828222Z",
     "shell.execute_reply": "2025-10-05T00:19:20.827587Z",
     "shell.execute_reply.started": "2025-10-05T00:19:20.819775Z"
    },
    "trusted": true
   },
   "source": [
    "@dataclass\n",
    "class TrainCfg:\n",
    "    downsample_factor: int = 4        \n",
    "    local_len: int = 1024\n",
    "    batch_size: int = 16\n",
    "    epochs: int = 80\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    amp: bool = False                 \n",
    "    monitor: str = \"val/pr_auc\"     \n",
    "    patience: int = 20                \n",
    "    ckpt_path: str = \"/kaggle/working/best.ckpt\"\n",
    "    project: str = \"exoplanets\"\n",
    "    entity: str = \"nasa-public_static_void_frogs\"\n",
    "    run_name: Optional[str] = \"without-50-candidates-realy-threshold-dynamic-planet=1\"\n",
    "    scheduler: str = \"plateau\"       \n",
    "    onecycle_max_lr: float = 2e-3\n",
    "    threshold: float = 0.65\n",
    "    loss_fn: Literal[\"bce\",\"bce_pos_weight\",\"focal\"] = \"focal\"\n",
    "    auto_pos_weight: bool = True\n",
    "    pos_weight: float | None = None\n",
    "    beta=1.5 \n",
    "    focal_gamma=1.5 \n",
    "    focal_alpha=0.30"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:49:25.265695Z",
     "iopub.status.busy": "2025-10-04T23:49:25.265111Z",
     "iopub.status.idle": "2025-10-04T23:49:25.270473Z",
     "shell.execute_reply": "2025-10-04T23:49:25.269915Z",
     "shell.execute_reply.started": "2025-10-04T23:49:25.265671Z"
    },
    "trusted": true
   },
   "source": [
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_prob: np.ndarray, threshold: float = 0.65):\n",
    "    y_pred = (y_prob >= threshold).astype(np.int32)\n",
    "    pr_auc = average_precision_score(y_true, y_prob)\n",
    "    roc = roc_auc_score(y_true, y_prob)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    cm   = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    return {\"pr_auc\": pr_auc, \"roc_auc\": roc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"cm\": cm}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T00:14:50.310538Z",
     "iopub.status.busy": "2025-10-05T00:14:50.309755Z",
     "iopub.status.idle": "2025-10-05T00:14:50.334509Z",
     "shell.execute_reply": "2025-10-05T00:14:50.333941Z",
     "shell.execute_reply.started": "2025-10-05T00:14:50.310513Z"
    },
    "trusted": true
   },
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model: nn.Module, cfg: TrainCfg):\n",
    "        self.model = model\n",
    "        self.cfg = cfg\n",
    "        self.device = torch.device(cfg.device)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.opt = torch.optim.AdamW(self.model.parameters(), lr=cfg.lr\n",
    "                                \n",
    "                                    )\n",
    "        self.scaler = torch.amp.GradScaler(enabled=cfg.amp) \n",
    "\n",
    "        if cfg.scheduler == \"plateau\":\n",
    "            self.sched = torch.optim.lr_scheduler.ReduceLROnPlateau(self.opt, mode=\"max\",\n",
    "                                                                    factor=0.5, patience=2, verbose=True)\n",
    "        elif cfg.scheduler == \"onecycle\":\n",
    "            self.sched = None\n",
    "        else:\n",
    "            self.sched = None\n",
    "        self.run = wandb.init(project=cfg.project, entity=cfg.entity, name=cfg.run_name, config=vars(cfg))\n",
    "        wandb.watch(self.model, log=\"all\", log_freq=200)\n",
    "\n",
    "        self.best_score = -float(\"inf\")\n",
    "        self.epochs_no_improve = 0\n",
    "        self.best_threshold = None  \n",
    "\n",
    "\n",
    "    def _forward_loss(self, batch, criterion):\n",
    "        gv, lv, y = batch\n",
    "        gv = gv.to(self.device, non_blocking=True)\n",
    "        lv = lv.to(self.device, non_blocking=True)\n",
    "        y  = y.to(self.device, non_blocking=True)\n",
    "        \n",
    "        with torch.autocast(device_type=(\"cuda\" if self.device.type==\"cuda\" else \"cpu\"),\n",
    "                            dtype=(torch.float16 if self.device.type==\"cuda\" else torch.bfloat16),\n",
    "                            enabled=self.cfg.amp):\n",
    "            logits = self.model(gv, lv)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "        return logits, y, loss\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, loader, criterion, epoch: int):\n",
    "        self.model.train()\n",
    "        total = 0; loss_sum = 0.0\n",
    "\n",
    "        if self.cfg.scheduler == \"onecycle\" and self.sched is None:\n",
    "            steps_per_epoch = len(loader)\n",
    "            self.sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                self.opt, max_lr=self.cfg.onecycle_max_lr,\n",
    "                epochs=self.cfg.epochs, steps_per_epoch=steps_per_epoch\n",
    "            )\n",
    "\n",
    "        for step, batch in enumerate(loader, 1):\n",
    "            self.opt.zero_grad(set_to_none=True)\n",
    "            logits, y, loss = self._forward_loss(batch, criterion)\n",
    "\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.opt)\n",
    "            self.scaler.update()\n",
    "            if isinstance(self.sched, torch.optim.lr_scheduler.OneCycleLR):\n",
    "                self.sched.step()\n",
    "\n",
    "            bs = y.size(0)\n",
    "            total += bs\n",
    "            loss_sum += loss.item() * bs\n",
    "\n",
    "            if step % 50 == 0:\n",
    "                wandb.log({\"train/loss_step\": loss.item(),\n",
    "                           \"train/lr\": self.opt.param_groups[0][\"lr\"],\n",
    "                           \"epoch\": epoch})\n",
    "\n",
    "        avg = loss_sum / max(1, total)\n",
    "        wandb.log({\"train/loss_epoch\": avg, \"epoch\": epoch})\n",
    "        return avg\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self, loader, criterion, split=\"val\", epoch: int = 0):\n",
    "        self.model.eval()\n",
    "        loss_sum = 0.0; total = 0\n",
    "        probs_all, y_all = [], []\n",
    "\n",
    "        for batch in loader:\n",
    "            logits, y, loss = self._forward_loss(batch, criterion)\n",
    "            prob = torch.sigmoid(logits).float().detach().cpu().numpy().reshape(-1)\n",
    "            yy   = y.detach().cpu().numpy().astype(np.int32).reshape(-1)\n",
    "\n",
    "            probs_all.append(prob); y_all.append(yy)\n",
    "            loss_sum += loss.item() * yy.shape[0]\n",
    "            total += yy.shape[0]\n",
    "\n",
    "        y_true = np.concatenate(y_all)\n",
    "        y_prob = np.concatenate(probs_all)\n",
    "\n",
    "        from sklearn.metrics import precision_recall_curve\n",
    "        prec, rec, thr = precision_recall_curve(y_true, y_prob)\n",
    "        f_beta = (1 + self.cfg.beta**2) * prec[:-1] * rec[:-1] / (self.cfg.beta**2 * prec[:-1] + rec[:-1] + 1e-9)\n",
    "        best_idx = int(np.nanargmax(f_beta))\n",
    "        best_thr = float(thr[best_idx]) if thr.size else 0.5\n",
    "        if split == \"val\":\n",
    "            self.best_threshold = best_thr \n",
    "        wandb.log({f\"{split}/threshold_bestF1\": best_thr, \"epoch\": epoch})\n",
    "\n",
    "        y_probas_2col = np.stack([1.0 - y_prob, y_prob], axis=1)\n",
    "        cm_plot = wandb.plot.confusion_matrix(\n",
    "            probs=y_probas_2col,\n",
    "            y_true=y_true.tolist(),\n",
    "            class_names=[\"neg\",\"pos\"],\n",
    "            title=f\"{split} Confusion Matrix\"\n",
    "        )\n",
    "        wandb.log({f\"{split}/confusion_matrix\": cm_plot})\n",
    "\n",
    "        pr_plot = wandb.plot.pr_curve(y_true=y_true.tolist(),\n",
    "                                      y_probas=y_probas_2col.tolist(),\n",
    "                                      labels=[\"neg\",\"pos\"])\n",
    "        roc_plot = wandb.plot.roc_curve(y_true=y_true.tolist(),\n",
    "                                        y_probas=y_probas_2col.tolist(),\n",
    "                                        labels=[\"neg\",\"pos\"])\n",
    "        wandb.log({f\"{split}/pr_curve\": pr_plot, f\"{split}/roc_curve\": roc_plot})\n",
    "\n",
    "        \n",
    "        metrics = compute_metrics(y_true, y_prob, threshold=best_thr)\n",
    "        avg_loss = loss_sum / max(1, total)\n",
    "\n",
    "        wandb.log({\n",
    "            f\"{split}/loss\": avg_loss,\n",
    "            f\"{split}/pr_auc\": metrics[\"pr_auc\"],\n",
    "            f\"{split}/roc_auc\": metrics[\"roc_auc\"],\n",
    "            f\"{split}/precision\": metrics[\"precision\"],\n",
    "            f\"{split}/recall\": metrics[\"recall\"],\n",
    "            f\"{split}/f1\": metrics[\"f1\"],\n",
    "            \"epoch\": epoch\n",
    "        })\n",
    "\n",
    "        if isinstance(self.sched, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            self.sched.step(metrics[\"pr_auc\"]) \n",
    "\n",
    "        return avg_loss, metrics\n",
    "\n",
    "    def _is_improved(self, metrics: dict) -> bool:\n",
    "        key = self.cfg.monitor.split(\"/\", 1)[-1] \n",
    "        return metrics.get(key, -1.0) > self.best_score\n",
    "\n",
    "\n",
    "    def fit(self, dl_tr: DataLoader, dl_va: DataLoader):\n",
    "        if self.cfg.loss_fn == \"bce\":\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        elif self.cfg.loss_fn == \"bce_pos_weight\":\n",
    "            if getattr(self.cfg, \"auto_pos_weight\", True):\n",
    "                pos = 0; neg = 0\n",
    "                for _, _, y in dl_tr:\n",
    "                    y = y.numpy()\n",
    "                    pos += (y == 1).sum()\n",
    "                    neg += (y == 0).sum()\n",
    "                pw = neg / max(1, pos)\n",
    "            else:\n",
    "                pw = self.cfg.pos_weight \n",
    "            criterion = nn.BCEWithLogitsLoss(\n",
    "                pos_weight=torch.tensor([pw], device=self.device)\n",
    "            )\n",
    "        elif self.cfg.loss_fn == \"focal\":\n",
    "            criterion = BinaryFocalLoss(gamma=self.cfg.focal_gamma, alpha=self.cfg.focal_alpha)\n",
    "        else:\n",
    "            raise ValueError(\"cfg.loss_fn must be one of: bce | bce_pos_weight | focal\")\n",
    "        \n",
    "\n",
    "        for ep in range(1, self.cfg.epochs + 1):\n",
    "            train_loss = self.train_one_epoch(dl_tr, criterion, ep)\n",
    "            val_loss, val_metrics = self.validate(dl_va, criterion, split=\"val\", epoch=ep)\n",
    "\n",
    "            current_score = val_metrics[self.cfg.monitor.split(\"/\",1)[-1]]\n",
    "            improved = self._is_improved(val_metrics)\n",
    "            if improved:\n",
    "                self.best_score = current_score\n",
    "                self.epochs_no_improve = 0\n",
    "                torch.save(self.model.state_dict(), self.cfg.ckpt_path)\n",
    "                wandb.run.summary[\"best_score\"] = float(self.best_score)\n",
    "                wandb.run.summary[\"best_ckpt\"] = self.cfg.ckpt_path\n",
    "            else:\n",
    "                self.epochs_no_improve += 1\n",
    "\n",
    "            print(f\"Epoch {ep:02d} | train_loss={train_loss:.4f} | \"\n",
    "                  f\"val_loss={val_loss:.4f} | PR-AUC={val_metrics['pr_auc']:.4f} | \"\n",
    "                  f\"ROC-AUC={val_metrics['roc_auc']:.4f}\")\n",
    "                  \n",
    "            if self.epochs_no_improve >= self.cfg.patience:\n",
    "                print(f\"Early stopping at epoch {ep} (no improve {self.cfg.patience} epochs).\")\n",
    "                break\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, dl_te: DataLoader):\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        _, te_metrics = self.validate(dl_te, criterion, split=\"test\", epoch=0)\n",
    "        if self.best_threshold is not None:\n",
    "            wandb.run.summary[\"best_val_threshold\"] = float(self.best_threshold)\n",
    "        print(\"TEST:\", te_metrics)\n",
    "        wandb.finish()\n",
    "        return te_metrics\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T00:14:57.434430Z",
     "iopub.status.busy": "2025-10-05T00:14:57.433697Z",
     "iopub.status.idle": "2025-10-05T00:17:17.503631Z",
     "shell.execute_reply": "2025-10-05T00:17:17.503028Z",
     "shell.execute_reply.started": "2025-10-05T00:14:57.434409Z"
    },
    "trusted": true
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_X = df_filled.drop(columns=[\"LABEL\"])\n",
    "y = df_filled[\"LABEL\"].to_numpy()\n",
    "\n",
    "y = (y == 0).astype(np.float32)\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    df_X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.15, random_state=42, stratify=y_trainval\n",
    ")\n",
    "\n",
    "print(f\"Shapes: train={X_train.shape}, val={X_val.shape}, test={X_test.shape}\")\n",
    "\n",
    "cfg = TrainCfg(epochs=80, scheduler=\"plateau\", patience=20, monitor=\"val/pr_auc\")\n",
    "\n",
    "ds_tr = DualViewDataset(X_train, y_train,\n",
    "                        downsample_factor=cfg.downsample_factor,\n",
    "                        local_len=cfg.local_len)\n",
    "ds_va = DualViewDataset(X_val, y_val,\n",
    "                        downsample_factor=cfg.downsample_factor,\n",
    "                        local_len=cfg.local_len)\n",
    "ds_te = DualViewDataset(X_test, y_test,\n",
    "                        downsample_factor=cfg.downsample_factor,\n",
    "                        local_len=cfg.local_len)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T00:17:17.505019Z",
     "iopub.status.busy": "2025-10-05T00:17:17.504780Z",
     "iopub.status.idle": "2025-10-05T00:17:17.515685Z",
     "shell.execute_reply": "2025-10-05T00:17:17.515185Z",
     "shell.execute_reply.started": "2025-10-05T00:17:17.504996Z"
    },
    "trusted": true
   },
   "source": [
    "dl_tr = DataLoader(ds_tr, batch_size=cfg.batch_size, shuffle=True,\n",
    "                   num_workers=2, pin_memory=True)\n",
    "dl_va = DataLoader(ds_va, batch_size=cfg.batch_size, shuffle=False,\n",
    "                   num_workers=2, pin_memory=True)\n",
    "dl_te = DataLoader(ds_te, batch_size=cfg.batch_size, shuffle=False,\n",
    "                   num_workers=2, pin_memory=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T00:29:33.711648Z",
     "iopub.status.busy": "2025-10-05T00:29:33.710920Z"
    },
    "trusted": true
   },
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "wandb.login(key=secret_value_0)\n",
    "\n",
    "\n",
    "model = DualViewNet(gv_width=128, lv_width=128)\n",
    "trainer = Trainer(model, cfg)\n",
    "trainer.fit(dl_tr, dl_va)    \n",
    "trainer.test(dl_te)          "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [
    " torch.save(model.state_dict(), 'DualViewNet.pth')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": true
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8353289,
     "sourceId": 13261092,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
